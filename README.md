# Whisper Speech Recognition

This repository contains the Python scripts and notebooks for a speech recognition project using the Whisper model, implemented in a Google Colab environment. The project focuses on leveraging advanced speech recognition technology to accurately transcribe spoken language, with a special emphasis on the MINDS-14 dataset.

## Table of Contents
- [Introduction](#introduction)
- [Dataset](#dataset)
- [Installation](#installation)
- [Usage](#usage)
- [Methodology](#methodology)
- [Results](#results)

## Introduction

This project aims to utilize the Whisper model for speech recognition, addressing challenges in understanding diverse accents and dialects in spoken language. It's designed to showcase the capabilities of state-of-the-art speech recognition technologies in handling complex audio data.

## Dataset

The project utilizes the MINDS-14 dataset, which is a comprehensive collection of spoken language samples. The dataset features a variety of languages, accents, and dialects, making it an ideal choice for testing the robustness and versatility of the Whisper model in speech recognition tasks.

## Installation

To run the scripts, the following dependencies are required:
- datasets
- matplotlib
- librosa
- seaborn
- evaluate
- jiwer
- accelerate
- transformers

Install all dependencies using the following command: pip install datasets matplotlib librosa seaborn evaluate jiwer accelerate transformers

## Usage

You can try out the model here: [Google Colab](https://colab.research.google.com/drive/1GPmQMYNKdDdoFOsoSsziuE-MTGOYqrzJ#scrollTo=Lxu2nMfW2guX)



